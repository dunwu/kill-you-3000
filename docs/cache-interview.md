# 缓存夺命连环问

## 为什么用缓存

用缓存，主要有两个用途：**高性能**、**高并发**。

### 高性能

假设这么个场景，你有个操作，一个请求过来，吭哧吭哧你各种乱七八糟操作 mysql，半天查出来一个结果，耗时 600ms。但是这个结果可能接下来几个小时都不会变了，或者变了也可以不用立即反馈给用户。那么此时咋办？

缓存啊，折腾 600ms 查出来的结果，扔缓存里，一个 key 对应一个 value，下次再有人查，别走 mysql 折腾 600ms 了，直接从缓存里，通过一个 key 查出来一个 value，2ms 搞定。性能提升 300 倍。

就是说对于一些需要复杂操作耗时查出来的结果，且确定后面不怎么变化，但是有很多读请求，那么直接将查询出来的结果放在缓存中，后面直接读缓存就好。

### 高并发

mysql 这么重的数据库，压根儿设计不是让你玩儿高并发的，虽然也可以玩儿，但是天然支持不好。mysql 单机支撑到 `2000QPS` 也开始容易报警了。

所以要是你有个系统，高峰期一秒钟过来的请求有 1 万，那一个 mysql 单机绝对会死掉。你这个时候就只能上缓存，把很多数据放缓存，别放 mysql。缓存功能简单，说白了就是 `key-value` 式操作，单机支撑的并发量轻松一秒几万十几万，支撑高并发 so easy。单机承载并发量是 mysql 单机的几十倍。

> 缓存是走内存的，内存天然就支撑高并发。

## 缓存淘汰算法

常见的缓存淘汰算法有以下几种：

- **FIFO** - 先进先出，在这种淘汰算法中，先进入缓存的会先被淘汰。这种可谓是最简单的了，但是会导致我们命中率很低。试想一下我们如果有个访问频率很高的数据是所有数据第一个访问的，而那些不是很高的是后面再访问的，那这样就会把我们的首个数据但是他的访问频率很高给挤出。
- **LRU** - 最近最少使用算法。在这种算法中避免了上面的问题，每次访问数据都会将其放在我们的队尾，如果需要淘汰数据，就只需要淘汰队首即可。但是这个依然有个问题，如果有个数据在 1 个小时的前 59 分钟访问了 1 万次(可见这是个热点数据),再后一分钟没有访问这个数据，但是有其他的数据访问，就导致了我们这个热点数据被淘汰。
- **LFU** - 最近最少频率使用。在这种算法中又对上面进行了优化，利用额外的空间记录每个数据的使用频率，然后选出频率最低进行淘汰。这样就避免了 LRU 不能处理时间段的问题。

这三种缓存淘汰算法，实现复杂度一个比一个高，同样的命中率也是一个比一个好。而我们一般来说选择的方案居中即可，即实现成本不是太高，而命中率也还行的 LRU。

一个简单的 LRU 实现：

```java
class LRUCache {

    private int capacity;

    // 保持插入顺序
    private Map<Integer, Integer> map;

    public LRUCache(int capacity) {
        this.capacity = capacity;
        map = new LinkedHashMap<>(capacity);
    }

    public int get(int key) {
        if (map.containsKey(key)) {
            int value = map.get(key);
            map.remove(key);
            // 保证每次查询后，都在末尾
            map.put(key, value);
            return value;
        }
        return -1;
    }

    public void put(int key, int value) {
        if (map.containsKey(key)) {
            map.remove(key);
        } else if (map.size() == capacity) {
            Iterator<Map.Entry<Integer, Integer>> iterator = map.entrySet().iterator();
            iterator.next();
            iterator.remove();
        }
        map.put(key, value);
    }

}
```

## 缓存方案技术选型

### 整体缓存方案（多级缓存）

实际的应用中，往往不是单独使用某一种缓存技术，而是组合使用多种缓存。

- **CDN 缓存** - 存放 HTML、CSS、JS 等静态资源。
- **反向代理缓存** - 动静分离，只缓存用户请求的静态资源。
- **进程内缓存** - 缓存应用字典等常用数据。
- **分布式缓存** - 缓存数据库中的热点数据。

![img](http://dunwu.test.upcdn.net/cs/java/javaweb/technology/cache/缓存整体架构.png)

上图展示了常见的缓存整体解决方案：

1. 浏览器向客户端发起请求，如果 CDN 有缓存则直接返回；
2. 如果 CDN 无缓存，则访问反向代理服务器；
3. 如果反向代理服务器有缓存则直接返回；
4. 如果反向代理服务器无缓存或动态请求，则访问应用服务器；
5. 应用服务器访问进程内缓存；如果有缓存，则返回代理服务器，并缓存数据；（动态请求不缓存）
6. 如果进程内缓存无数据，则读取分布式缓存；并返回应用服务器；应用服务器将数据缓存到本地缓存（部分）；
7. 如果分布式缓存无数据，则应用程序读取数据库数据，并放入分布式缓存；

Java 应用主要关注的是进程内缓存和分布式缓存。

### 进程内缓存

常见的本地缓存实现方案：HashMap、Guava Cache、Caffeine、Ehcache。

技术对比：

| 比较项       | ConcurrentHashMap | LRUMap                   | Ehcache                       | Guava Cache                         | Caffeine                |
| ------------ | ----------------- | ------------------------ | ----------------------------- | ----------------------------------- | ----------------------- |
| 读写性能     | 很好，分段锁      | 一般，全局加锁           | 好                            | 好，需要做淘汰操作                  | 很好                    |
| 淘汰算法     | 无                | LRU，一般                | 支持多种淘汰算法,LRU,LFU,FIFO | LRU，一般                           | W-TinyLFU, 很好         |
| 功能丰富程度 | 功能比较简单      | 功能比较单一             | 功能很丰富                    | 功能很丰富，支持刷新和虚引用等      | 功能和 Guava Cache 类似 |
| 工具大小     | jdk 自带类，很小  | 基于 LinkedHashMap，较小 | 很大，最新版本 1.4MB          | 是 Guava 工具类中的一个小部分，较小 | 一般，最新版本 644KB    |
| 是否持久化   | 否                | 否                       | 是                            | 否                                  | 否                      |
| 是否支持集群 | 否                | 否                       | 是                            | 否                                  | 否                      |

- **`ConcurrentHashMap`** - 比较适合缓存比较固定不变的元素，且缓存的数量较小的。虽然从上面表格中比起来有点逊色，但是其由于是 JDK 自带的类，在各种框架中依然有大量的使用，比如我们可以用来缓存我们反射的 Method，Field 等等；也可以缓存一些链接，防止其重复建立。在 Caffeine 中也是使用的 `ConcurrentHashMap` 来存储元素。
- **`LRUMap`** - 如果不想引入第三方包，又想使用淘汰算法淘汰数据，可以使用这个。
- **`Ehcache`** - 由于其 jar 包很大，较重量级。对于需要持久化和集群的一些功能的，可以选择 Ehcache。需要注意的是，虽然 Ehcache 也支持分布式缓存，但是由于其节点间通信方式为 rmi，表现不如 Redis，所以一般不建议用它来作为分布式缓存。
- **`Guava Cache`** - Guava 这个 jar 包在很多 Java 应用程序中都有大量的引入，所以很多时候其实是直接用就好了，并且其本身是轻量级的而且功能较为丰富，在不了解 Caffeine 的情况下可以选择 Guava Cache。
- **`Caffeine`** - 其在命中率，读写性能上都比 Guava Cache 好很多，并且其 API 和 Guava cache 基本一致，甚至会多一点。在真实环境中使用 Caffeine，取得过不错的效果。

总结一下：如果不需要淘汰算法则选择 `ConcurrentHashMap`，如果需要淘汰算法和一些丰富的 API，推荐选择 Caffeine。

### 分布式缓存

这里选取三个比较出名的分布式缓存（MemCache，Redis，Tair）来作为比较：

| 比较项   | MemCache                     | Redis                                  | Tair                                                      |
| -------- | ---------------------------- | -------------------------------------- | --------------------------------------------------------- |
| 数据结构 | 只支持简单的 Key-Value 结构  | String,Hash, List, Set, Sorted Set     | String,HashMap, List，Set                                 |
| 持久化   | 不支持                       | 支持                                   | 支持                                                      |
| 容量大小 | 数据纯内存，数据存储不宜过多 | 数据全内存，资源成本考量不宜超过 100GB | 可以配置全内存或内存+磁盘引擎，数据容量可无限扩充         |
| 读写性能 | 很高                         | 很高(RT0.5ms 左右)                     | String 类型比较高(RT1ms 左右)，复杂类型比较慢(RT5ms 左右) |
| 过期策略 | 过期后，不删除缓存           | 有多种过期策略                         | 支持                                                      |

- `MemCache` - 这一块接触得比较少，不做过多的推荐。其吞吐量较大，但是支持的数据结构较少，并且不支持持久化。
- `Redis` - 支持丰富的数据结构，读写性能很高，但是数据全内存，必须要考虑资源成本，支持持久化。
- `Tair` - 支持丰富的数据结构，读写性能较高，部分类型比较慢，理论上容量可以无限扩充。

总结：如果服务对延迟比较敏感，Map/Set 数据也比较多的话，比较适合 Redis。如果服务需要放入缓存量的数据很大，对延迟又不是特别敏感的话，那就可以选择 Tair。

## 缓存常见问题

### 缓存雪崩

> **缓存雪崩是指缓存不可用或者大量缓存由于超时时间相同在同一时间段失效，大量请求直接访问数据库，数据库压力过大导致系统雪崩**。

缓存雪崩的事前事中事后的解决方案如下：

- 事前：Redis 高可用，使用 Redis Cluster（主从+哨兵），避免全盘崩溃。
- 事中：本地缓存（Ehcache/Caffine/Google Cache） + Hystrix 限流&降级，避免数据库崩溃。
- 事后：Redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。

上面的解决方案简单来说，就是多级缓存方案。系统收到一个查询请求，先查本地缓存，再查分布式缓存，最后查数据库，只要命中，立即返回。

辅助性手段：

- 通过监控关注缓存的健康程度，根据业务量适当的扩容缓存。
- 缓存的过期时间可以取个随机值。比如以前是设置 10 分钟的超时时间，那每个 Key 都可以随机 8-13 分钟过期，尽量让不同 Key 的过期时间不同。

### 缓存穿透

> **缓存穿透是指：查询的数据在数据库中不存在，那么缓存中自然也不存在。所以，应用在缓存中查不到，则会去查询数据库。当这样的请求多了后，数据库的压力就会增大。**

解决缓存穿透，一般有两种方法：

- **对于返回为 NULL 的依然缓存，对于抛出异常的返回不进行缓存**。

<div align="center"><img src="http://dunwu.test.upcdn.net/cs/java/javaweb/technology/cache/缓存穿透1.png!zp" width="350px"/></div>

采用这种手段的会增加我们缓存的维护成本，需要在插入缓存的时候删除这个空缓存，当然我们可以通过设置较短的超时时间来解决这个问题。

- **过滤不可能存在的数据**

<div align="center"><img src="http://dunwu.test.upcdn.net/cs/java/javaweb/technology/cache/缓存穿透2.png!zp" width="350px"/></div>

**制定一些规则过滤一些不可能存在的数据**。小数据用 BitMap，大数据可以用布隆过滤器，比如你的订单 ID 明显是在一个范围 1-1000，如果不是 1-1000 之内的数据那其实可以直接给过滤掉。

### 缓存击穿

缓存击穿是指，某些 key 是热点数据，访问非常频繁。如果某个 key 失效的瞬间，大量的请求过来，缓存未命中，然后去数据库访问，此时数据库访问量会急剧增加。

为了避免这个问题，我们可以采取下面的两个手段:

- **分布式锁** - 锁住热点数据的 key，避免大量线程同时访问同一个 key。
- **异步加载** - 可以对部分数据采取到期自动刷新的策略，而不是到期自动淘汰。淘汰其实也是为了数据的时效性，所以采用自动刷新也可以。

### 缓存更新

一般来说，系统如果不是严格要求缓存和数据库保持一致性的话，尽量不要将**读请求和写请求串行化**。串行化可以保证一定不会出现数据不一致的情况，但是它会导致系统的吞吐量大幅度下降。

一般来说缓存的更新有两种情况:

- 先删除缓存，再更新数据库。
- 先更新数据库，再删除缓存。

> **为什么是删除缓存，而不是更新缓存呢？**
>
> 你可以想想当有多个并发的请求更新数据，你并不能保证更新数据库的顺序和更新缓存的顺序一致，那就会出现数据库中和缓存中数据不一致的情况。所以一般来说考虑删除缓存。

- **先删除缓存，再更新数据库**

对于一个更新操作简单来说，就是先去各级缓存进行删除，然后更新数据库。

这个操作有一个比较大的问题，在对缓存删除完之后，有一个读请求，这个时候由于缓存被删除所以直接会读库，读操作的数据是老的并且会被加载进入缓存当中，后续读请求全部访问的老数据。

<div align="center"><img src="http://dunwu.test.upcdn.net/cs/java/javaweb/technology/cache/缓存更新.png!zp" width="400px"/></div>

对缓存的操作不论成功失败都不能阻塞我们对数据库的操作，那么很多时候删除缓存可以用异步的操作，但是先删除缓存不能很好的适用于这个场景。

先删除缓存也有一个好处是，如果对数据库操作失败了，那么由于先删除的缓存，最多只是造成 Cache Miss。

- **先更新数据库，再删除缓存**

> 注：更推荐使用这种策略

如果我们使用更新数据库，再删除缓存就能避免上面的问题。

但是同样的引入了新的问题：假设执行更新操作时，又接收到查询请求，此时就会返回缓存中的老数据。更麻烦的是，如果数据库更新操作执行失败，则缓存中可能永远是脏数据。

- 应该选择哪种更新策略

通过上面的内容，我们知道，两种更新策略都存在并发问题。

但是建议选择先更新数据库，再删除缓存，因为其并发问题出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且同时有一个并发写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。

如果需要数据库和缓存保证强一致性，则可以通过 2PC 或 Paxos 协议来实现。但是 2PC 太慢，而 Paxos 太复杂，所以如果不是非常重要的数据，不建议使用强一致性方案。

### 缓存预热

缓存预热是指系统启动后，将常用的数据直接缓存。这样就可以避免用户请求的时候，先查询数据库，然后再更新缓存的问题。

解决方案：

- 直接写个缓存刷新页面，上线时手工操作下。
- 数据量不大，可以在项目启动的时候自动进行加载。
- 定时刷新缓存。

### 缓存降级

当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。

降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。

## Redis 特性

由于 Redis 是目前最流行的分布式缓存方案，所以缓存问题总是会绑定着 Redis 特性一起问。

### Redis 数据类型

- 问题：

  - Redis 数据类型有哪些？
  - Redis 各种数据类型适用于什么样的场景？

------

解答：

Redis 基本数据类型：

| 数据类型 | 可以存储的值           | 操作                                                         |
| -------- | ---------------------- | ------------------------------------------------------------ |
| STRING   | 字符串、整数或者浮点数 | 对整个字符串或者字符串的其中一部分执行操作</br> 对整数和浮点数执行自增或者自减操作 |
| LIST     | 列表                   | 从两端压入或者弹出元素</br> 读取单个或者多个元素</br> 进行修剪，只保留一个范围内的元素 |
| SET      | 无序集合               | 添加、获取、移除单个元素</br> 检查一个元素是否存在于集合中</br> 计算交集、并集、差集</br> 从集合里面随机获取元素 |
| HASH     | 包含键值对的无序散列表 | 添加、获取、移除单个键值对</br> 获取所有键值对</br> 检查某个键是否存在 |
| ZSET     | 有序集合               | 添加、获取、删除元素</br> 根据分值范围或者成员来获取元素</br> 计算一个键的排名 |

Redis 各种数据类型的应用比较繁杂，详情可以参考：[Redis 数据类型](https://github.com/dunwu/db-tutorial/blob/master/docs/nosql/redis/redis-datatype.md)

### Redis 内存淘汰

问题：

- Redis 有哪些淘汰策略？
- 这些淘汰策略分别适用于什么场景？
- Redis 有哪些删除失效 key 的方法？
- 如何设置 Redis 中键的过期时间？
- 如果让你实现一个 LRU 算法，怎么做？

---

解答：

Redis 提供了下面几种内存淘汰策略供用户选：

- **`noeviction`** - 当内存使用达到阈值的时候，所有引起申请内存的命令会报错。这是 Redis 默认的策略。
- **`allkeys-lru`** - 在主键空间中，优先移除最近未使用的 key。
- **`allkeys-random`** - 在主键空间中，随机移除某个 key。
- **`volatile-lru`** - 在设置了过期时间的键空间中，优先移除最近未使用的 key。
- **`volatile-random`** - 在设置了过期时间的键空间中，随机移除某个 key。
- **`volatile-ttl`** - 在设置了过期时间的键空间中，具有更早过期时间的 key 优先移除。

如何选择内存淘汰策略：

- 如果数据呈现幂等分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用 `allkeys-lru`。
- 如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用 `allkeys-random`。
- `volatile-lru` 策略和 `volatile-random` 策略适合我们将一个 Redis 实例既应用于缓存和又应用于持久化存储的时候，然而我们也可以通过使用两个 Redis 实例来达到相同的效果。
- 将 key 设置过期时间实际上会消耗更多的内存，因此我们建议使用 `allkeys-lru` 策略从而更有效率的使用内存。

Redis 删除失效主键的方法主要有两种：

- 消极方法（passive way），在主键被访问时如果发现它已经失效，那么就删除它。
- 主动方法（active way），周期性地从设置了失效时间的主键中选择一部分失效的主键删除。

### Redis 持久化

问题：

- Redis 有哪些持久化方式？
- Redis 的不同持久化方式的特性和原理是什么？
- RDB 和 AOF 各有什么优缺点？分别适用于什么样的场景？
- Redis 执行持久化时，可以处理请求吗？
- AOF 有几种同步频率？

---

解答：

Redis 支持两种持久化方式：RDB 和 AOF。

RDB 即快照方式，它将某个时间点的所有 Redis 数据保存到一个经过压缩的二进制文件（RDB 文件）中。

AOF(Append Only File) 是以文本日志形式将所有写命令追加到 AOF 文件的末尾，以此来记录数据的变化。

更详细的特性及原理说明请参考：[Redis 持久化](https://github.com/dunwu/db-tutorial/blob/master/docs/nosql/redis/redis-persistence.md)

### Redis 高并发

问题：

- Redis 是单线程模型，为何吞吐量还很高？
- Redis 集群如何分片和寻址？
- Redis 集群如何扩展？
- Redis 集群如何保证数据一致？
- Redis 集群如何规划？你们公司的生产环境上如何部署 Redis 集群？

---

解答：

Redis 单机吞吐量也很高，能达到几万 QPS，但需要格外注意的是：**Redis 是单线程模型**。很多人可能会奇怪，Redis 是单线程模型，如何能处理高并发请求呢？

原因在于：

- Redis 读写都是内存操作。
- Redis 基于**非阻塞的 IO 多路复用机制**，同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。
- 单线程，避免了线程创建、销毁、上下文切换的开销，并且避免了资源竞争。

Redis 的高并发通过主从架构来实现。Redis 集群采用主从模型，提供复制和故障转移功能，来保证 Redis 集群的高可用。通常情况，一主多从模式已经可以满足大部分项目的需要。根据实际的并发量，可以通过增加节点来扩展并发吞吐。

一主多从模式下，主节点负责写操作（单机几万 QPS），从节点负责查询操作（单机十万 QPS）。

进一步，如果需要缓存大量数据，就需要分区（sharding），Redis 集群通过划分虚拟 hash 槽来分片，进行数据分享。

根据 CAP 理论，Consistency、Availability、Partition tolerance 三者不可兼得，而 Redis 集群的选择是 AP。Redis 集群节点间采用异步通信方式，不保证强一致性，尽力达到最终一致性。

`Redis` 集群一般由 **多个节点** 组成，节点数量至少为 `6` 个，才能保证组成 **完整高可用** 的集群。

![img](https://user-gold-cdn.xitu.io/2019/10/10/16db5250b0d1c392?w=1467&h=803&f=png&s=43428)

更详细的特性及原理说明请参考：[Redis 集群](https://github.com/dunwu/db-tutorial/blob/master/docs/nosql/redis/redis-cluster.md)

### Redis 高可用

问题：

- Redis 如何实现高可用？
- Redis 哨兵的功能？
- Redis 哨兵的原理？
- Redis 哨兵如何选举 Leader？
- Redis 如何实现故障转移？

---

解答：

Redis 的高可用是通过哨兵来实现（Raft 协议的 Redis 实现）。Sentinel（哨兵）可以监听主服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。

由一个或多个 Sentinel 实例组成的 Sentinel 系统可以监视任意多个主服务器，以及这些主服务器的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线主服务器的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求。

![img](http://dunwu.test.upcdn.net/snap/20200131135847.png)

更详细的特性及原理说明请参考：[Redis 哨兵](https://github.com/dunwu/db-tutorial/blob/master/docs/nosql/redis/redis-sentinel.md)

### Redis 复制

问题：

- Redis 复制的工作原理？Redis 旧版复制和新版复制有何不同？
- Redis 主从节点间如何复制数据？
- Redis 的数据一致性是强一致性吗？

---

解答：

旧版复制基于 `SYNC` 命令实现。分为同步（sync）和命令传播（command propagate）两个操作。这种方式存在缺陷：不能高效处理断线重连后的复制情况。

新版复制基于 `PSYNC` 命令实现。同步操作分为了两块：

- **`完整重同步（full resychronization）`** 用于初次复制；
- **`部分重同步（partial resychronization）`** 用于断线后重复制。
  - 主从服务器的**复制偏移量（replication offset）**
  - 主服务器的**复制积压缓冲区（replication backlog）**
  - **服务器的运行 ID**

Redis 集群主从节点复制的工作流程：

- 步骤 1. 设置主从服务器
- 步骤 2. 主从服务器建立 TCP 连接。
- 步骤 3. 发送 PING 检查通信状态。
- 步骤 4. 身份验证。
- 步骤 5. 发送端口信息。
- 步骤 6. 同步。
- 步骤 7. 命令传播。

更详细的特性及原理说明请参考：[Redis 复制](https://github.com/dunwu/db-tutorial/blob/master/docs/nosql/redis/redis-replication.md)

### Redis 事务

问题：

- Redis 支持事务吗？
- Redis 事务是严格意义的事务吗？Redis 为什么不支持回滚。
- Redis 事务如何工作？
- 了解 Redis 事务中的 CAS 行为吗？
- 除了事务，还有其他批量执行 Redis 命令的方式吗？

解答：

**Redis 提供的不是严格的事务，Redis 只保证串行执行命令，并且能保证全部执行，但是执行命令失败时并不会回滚，而是会继续执行下去**。

Redis 不支持回滚的理由：

- Redis 命令只会因为错误的语法而失败，或是命令用在了错误类型的键上面。
- 因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。

`MULTI` 、 `EXEC` 、 `DISCARD` 和 `WATCH` 是 Redis 事务相关的命令。

- **[`MULTI`](https://redis.io/commands/multi) 命令用于开启一个事务，它总是返回 OK 。**
- **[`EXEC`](https://redis.io/commands/exec) 命令负责触发并执行事务中的所有命令。**
- **当执行 [`DISCARD`](https://redis.io/commands/discard) 命令时， 事务会被放弃， 事务队列会被清空， 并且客户端会从事务状态中退出。**
- **[`WATCH`](https://redis.io/commands/watch) 命令可以为 Redis 事务提供 check-and-set （CAS）行为。**被 WATCH 的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在 EXEC 执行之前被修改了， 那么整个事务都会被取消， EXEC 返回 nil-reply 来表示事务已经失败。

Redis 是一种基于 C/S 模型以及请求/响应协议的 TCP 服务。Redis 支持管道技术。管道技术允许请求以异步方式发送，即旧请求的应答还未返回的情况下，允许发送新请求。这种方式可以大大提高传输效率。使用管道发送命令时，Redis Server 会将部分请求放到缓存队列中（占用内存），执行完毕后一次性发送结果。如果需要发送大量的命令，会占用大量的内存，因此应该按照合理数量分批次的处理。
